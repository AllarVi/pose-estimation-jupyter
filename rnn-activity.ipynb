{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from path import Path\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Bidirectional\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import random\n",
    "\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_active_keypoints(frame_df):\n",
    "    #active_keypoints = [0, 1, 8, 2, 3, 4, 5, 6, 7] # trunk\n",
    "    \n",
    "    active_keypoints = [0, 1, 8, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14]\n",
    "    \n",
    "    #filtered_df  = frame_df[frame_df.index.isin(active_keypoints)]\n",
    "    filtered_df = frame_df\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def get_frame_data(filepath):\n",
    "    frame_data = pd.read_csv(filepath)\n",
    "    \n",
    "    x_data = filter_active_keypoints(frame_data.iloc[:, 0])\n",
    "    y_data = filter_active_keypoints(frame_data.iloc[:, 1])\n",
    "    \n",
    "    #print(f\"x_data shape: {x_data.shape}\")\n",
    "    #print(f\"y_data shape: {y_data.shape}\")\n",
    "        \n",
    "    h_stacked = np.hstack((x_data, y_data))\n",
    "    #h_stacked = np.hstack((y_data))\n",
    "    \n",
    "    return h_stacked\n",
    "\n",
    "def get_frame_file_path(frame_file_path_template, frame_idx):\n",
    "    frame_file_path = frame_file_path_template.replace(\"[frame_idx]\", str(frame_idx))\n",
    "    return frame_file_path\n",
    "\n",
    "def get_label(sample_dir_name):\n",
    "    return 0 if sample_dir_name[0] == 'b' else 1\n",
    "\n",
    "def get_y_labels(sample_dir_names):\n",
    "    return [get_label(l) for l in sample_dir_names]\n",
    "\n",
    "def get_frames_count(root_path, sample_dir_name):\n",
    "    return len([Path(f).abspath() for f in glob(f\"{root_path}/{sample_dir_name}\" + '/*')])\n",
    "\n",
    "def get_frames(root_path, sample_dir_name):\n",
    "    frames = []\n",
    "    for frame_idx in range(0, get_frames_count(root_path, sample_dir_name)):\n",
    "        frame_file_path_template = f\"{root_path}/{sample_dir_name}/{sample_dir_name}.mov-[frame_idx]-0.csv\"\n",
    "        frame_file_path = get_frame_file_path(frame_file_path_template, frame_idx)\n",
    "        frame_data = get_frame_data(frame_file_path)\n",
    "        \n",
    "        frames.append(frame_data)\n",
    "        \n",
    "    return np.dstack(frames)\n",
    "\n",
    "def get_sample_idx_by_frames_count(frames_count, samples):\n",
    "    sample_idx = 0\n",
    "    \n",
    "    for sample in samples:\n",
    "        if len(sample) == frames_count:\n",
    "            return sample_idx\n",
    "        sample_idx = sample_idx + 1\n",
    "\n",
    "def get_sample_name_by_frames_count(frames_count, samples, sample_dir_names):\n",
    "    sample_idx = get_sample_idx_by_frames_count(frames_count, samples)\n",
    "    return sample_dir_names[sample_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"/Users/allarviinamae/EduWorkspace/openpose-jupyter-data-exploration/centered-keypoints\"\n",
    "\n",
    "sample_dir_names = [n for n in os.listdir(root_path) if os.path.isdir(f\"{root_path}/{n}\")]\n",
    "\n",
    "# ['backflip-40-margus',\n",
    "# 'flack-31-rasmus',\n",
    "# 'flack-19-rasmus',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_labels = get_y_labels(sample_dir_names) # classifier labels, where 0 = backflip and 1 = flack\n",
    "\n",
    "# [0,\n",
    "# 1,\n",
    "# 1,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "for sample_dir_name in sample_dir_names:\n",
    "    frames = get_frames(root_path, sample_dir_name)\n",
    "    squeezed = np.squeeze(frames)\n",
    "    axes_swapped = np.swapaxes(squeezed, 0, 1)\n",
    "    samples.append(axes_swapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shortest samples 77, longest sample 110\n",
      "113 (96, 50) 113\n"
     ]
    }
   ],
   "source": [
    "shortest_sample = min([len(sample) for sample in samples])\n",
    "longest_sample = max([len(sample) for sample in samples])\n",
    "\n",
    "print(f\"Shortest samples {shortest_sample}, longest sample {longest_sample}\")\n",
    "\n",
    "print(len(samples), samples[1].shape, len(y_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Samples')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(sample) for sample in samples], color = 'blue', edgecolor = 'black', bins = int(180/5))\n",
    "\n",
    "# Add labels\n",
    "plt.title('Histogram of Frames per Sample')\n",
    "plt.xlabel('Frames')\n",
    "plt.ylabel('Samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'backflip-50-joosep'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sample_name_by_frames_count(110, samples, sample_dir_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All labels shape (113, 2)\n",
      "y_label_squeezed categorical: [1. 0.]\n",
      "y_label_squeezed categorical: [0. 1.]\n",
      "y_label_squeezed categorical: [0. 1.]\n",
      "y_label_squeezed categorical: [0. 1.]\n",
      "y_label_squeezed categorical: [1. 0.]\n"
     ]
    }
   ],
   "source": [
    "y_labels_stacked = np.dstack(y_labels)\n",
    "y_labels_categorical = to_categorical(y_labels_stacked) \n",
    "y_labels_squeezed = np.squeeze(y_labels_categorical)\n",
    "print(f\"All labels shape {y_labels_squeezed.shape}\")\n",
    "\n",
    "for idx, y_label_squeezed in enumerate(y_labels_squeezed):\n",
    "    if idx == 5:\n",
    "        break\n",
    "    print(f\"y_label_squeezed categorical: {y_label_squeezed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train len 90, y_train len 90\n",
      "X_test len 23, y_test len 23\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(samples, y_labels_squeezed, test_size=0.2)\n",
    "\n",
    "print(f\"X_train len {len(X_train)}, y_train len {len(y_train)}\")\n",
    "print(f\"X_test len {len(X_test)}, y_test len {len(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(samples, y_labels):\n",
    "    while True:\n",
    "        random.shuffle(samples)\n",
    "\n",
    "        for idx, sample in enumerate(samples):\n",
    "            (frames, features) = sample.shape\n",
    "        \n",
    "            sequence_length = frames\n",
    "            x_train = sample\n",
    "            y_train = y_labels[idx]\n",
    "        \n",
    "            x_train = x_train.reshape(1, frames, features)\n",
    "            y_train = y_train.reshape(1, 2)            \n",
    "        \n",
    "            yield x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "    verbose, epochs = 1, 10\n",
    "    \n",
    "    n_features = 50\n",
    "    n_outputs = 2\n",
    "    n_steps_per_epoch = len(trainX)\n",
    "    n_steps_per_epoch = 360\n",
    "    \n",
    "    lstm_units = 100\n",
    "    \n",
    "    optimizer = Adam(lr=0.001)\n",
    "        \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(lstm_units, input_shape=(None, n_features)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(lstm_units, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    print(model.summary())\n",
    "    # fit network\n",
    "    model.fit_generator(train_generator(trainX, trainy), steps_per_epoch=n_steps_per_epoch, epochs=epochs, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy = model.evaluate_generator(train_generator(testX, testy), steps=len(testX), verbose=0)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_results(scores):\n",
    "    print(scores)\n",
    "    m, s = mean(scores), std(scores)\n",
    "    print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run an experiment\n",
    "def run_experiment(repeats=5):\n",
    "    # repeat experiment\n",
    "    scores = list()\n",
    "    for r in range(repeats):\n",
    "        score = evaluate_model(X_train, y_train, X_test, y_test)\n",
    "        score = score * 100.0\n",
    "        print('>#%d validation accuracy: %.3f' % (r+1, score))\n",
    "        scores.append(score)\n",
    "    # summarize results\n",
    "    summarize_results(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 100)               60400     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 70,702\n",
      "Trainable params: 70,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "360/360 [==============================] - 16s 46ms/step - loss: 0.7807 - accuracy: 0.4833\n",
      "Epoch 2/10\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.7677 - accuracy: 0.4806\n",
      "Epoch 3/10\n",
      "360/360 [==============================] - 18s 50ms/step - loss: 0.7361 - accuracy: 0.5139\n",
      "Epoch 4/10\n",
      "360/360 [==============================] - 16s 46ms/step - loss: 0.7309 - accuracy: 0.4667\n",
      "Epoch 5/10\n",
      "360/360 [==============================] - 17s 48ms/step - loss: 0.7391 - accuracy: 0.4500\n",
      "Epoch 6/10\n",
      "360/360 [==============================] - 19s 52ms/step - loss: 0.7417 - accuracy: 0.4000\n",
      "Epoch 7/10\n",
      "360/360 [==============================] - 21s 60ms/step - loss: 0.7005 - accuracy: 0.5194\n",
      "Epoch 8/10\n",
      "360/360 [==============================] - 20s 56ms/step - loss: 0.7234 - accuracy: 0.4639\n",
      "Epoch 9/10\n",
      " 88/360 [======>.......................] - ETA: 14s - loss: 0.7054 - accuracy: 0.4205"
     ]
    }
   ],
   "source": [
    "run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openpose-jupyter-data-exploration",
   "language": "python",
   "name": "openpose-jupyter-data-exploration"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

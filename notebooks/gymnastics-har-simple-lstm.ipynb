{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "\n",
    "from numpy import dstack\n",
    "\n",
    "import copy\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from path import Path\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import SimpleRNN\n",
    "\n",
    "from keras.layers import Bidirectional\n",
    "\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.classes.data_loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"/Users/allarviinamae/EduWorkspace/openpose-jupyter-data-exploration/centered-keypoints\"\n",
    "\n",
    "sample_dir_names = [n for n in os.listdir(root_path) if os.path.isdir(f\"{root_path}/{n}\")]\n",
    "\n",
    "samples = DataLoader.get_samples_list(sample_dir_names, root_path)\n",
    "\n",
    "y_labels = DataLoader.get_y_labels(sample_dir_names) # classifier labels, where 0 = backflip and 1 = flack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backflip-40-margus\n",
      "flack-31-rasmus\n",
      "flack-19-rasmus\n",
      "flack-59-martin\n",
      "backflip-66-allar\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "i = 5\n",
    "\n",
    "# Print some sample dir names\n",
    "a = [print(sample_dir_name) for sdn_i, sample_dir_name in enumerate(sample_dir_names) if sdn_i < i]\n",
    "a = [print(y_label) for y_i, y_label in enumerate(y_labels) if y_i < i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.classes.padder import Padder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_labels_stacked shape: (1, 1, 113)\n",
      "y_labels_categorical shape: (1, 1, 113, 2)\n",
      "y_labels_squeezed shape (113, 2)\n",
      "y_label categorical: [1.0, 0.0]\n",
      "y_label categorical: [0.0, 1.0]\n",
      "y_label categorical: [0.0, 1.0]\n",
      "y_label categorical: [0.0, 1.0]\n",
      "y_label categorical: [1.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "padded_samples_list = Padder.get_padded_samples(samples)\n",
    "categorical_y_labels = DataLoader.get_categorical_y_labels(y_labels)\n",
    "\n",
    "padded_samples_ndarray = np.asarray(padded_samples_list)\n",
    "categorical_y_labels_ndarray = np.asarray(categorical_y_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simple_lstm_model(lstm_units, n_outputs, n_features, n_timesteps):\n",
    "    optimizer = Adam(lr=0.001)\n",
    "        \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(lstm_units, input_shape=(n_timesteps, n_features)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(lstm_units, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "    verbose, epochs = 1, 15\n",
    "    \n",
    "    #n_steps_per_epoch = 360\n",
    "    \n",
    "    lstm_units = 2\n",
    "\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "    model = get_simple_lstm_model(lstm_units, n_outputs, n_features, n_timesteps)\n",
    "    \n",
    "    \n",
    "    print(model.summary())\n",
    "    plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
    "    \n",
    "    batch_size = 1\n",
    "    \n",
    "    es_callback = EarlyStopping(monitor='val_loss', patience=3)\n",
    "    \n",
    "    history = model.fit(trainX,\n",
    "                        trainy,\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        verbose=verbose,\n",
    "                        validation_split=0.33,\n",
    "                        callbacks=[es_callback])\n",
    "    # evaluate model\n",
    "    _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "    \n",
    "    # fit network\n",
    "    #model.fit_generator(train_generator(trainX, trainy), steps_per_epoch=n_steps_per_epoch, epochs=epochs, verbose=verbose)\n",
    "    # evaluate model\n",
    "    #_, accuracy = model.evaluate_generator(train_generator(testX, testy), steps=len(testX), verbose=0)\n",
    "    \n",
    "    return history, accuracy, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_results(scores):\n",
    "    print(scores)\n",
    "    m, s = mean(scores), std(scores)\n",
    "    print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, repeat):\n",
    "    # serialize model to JSON\n",
    "    model_json = model.to_json()\n",
    "    with open(f\"model-{repeat}.json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(f\"model-{repeat}.h5\")\n",
    "    print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train len: 90, y train len:90 --- X test len:23, y test len:23\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(padded_samples_ndarray,\n",
    "                                                    categorical_y_labels_ndarray,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "\n",
    "print(f\"X train len: {len(X_train)}, y train len:{len(y_train)} --- X test len:{len(X_test)}, y test len:{len(y_test)}\")\n",
    "\n",
    "train_loss_history = DataFrame()\n",
    "val_loss_history = DataFrame()\n",
    "\n",
    "train_accuracy_history = DataFrame()\n",
    "val_accuracy_history = DataFrame()\n",
    "# run an experiment\n",
    "def run_experiment(repeats=5):\n",
    "    # repeat experiment\n",
    "    scores = list()\n",
    "    last_history = None\n",
    "    \n",
    "    for r in range(repeats):\n",
    "        history, score, model = evaluate_model(X_train, y_train, X_test, y_test)\n",
    "        #model, score = evaluate_model(UtrainX, Utrainy, UtestX, Utesty)\n",
    "        save_model(model, r)\n",
    "        \n",
    "        # story history\n",
    "        train_loss_history[str(r)] = history.history['loss']\n",
    "        val_loss_history[str(r)] = history.history['val_loss']\n",
    "        train_accuracy_history[str(r)] = history.history['accuracy']\n",
    "        val_accuracy_history[str(r)] = history.history['val_accuracy']\n",
    "        \n",
    "        score = score * 100.0\n",
    "        print('>#%d validation accuracy: %.3f' % (r+1, score))\n",
    "        scores.append(score)\n",
    "        \n",
    "    # summarize results\n",
    "    summarize_results(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 2)                 264       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 6         \n",
      "=================================================================\n",
      "Total params: 276\n",
      "Trainable params: 276\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 60 samples, validate on 30 samples\n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 4s 64ms/step - loss: 0.6939 - accuracy: 0.5167 - val_loss: 0.6895 - val_accuracy: 0.7000\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 2s 41ms/step - loss: 0.6930 - accuracy: 0.5333 - val_loss: 0.6871 - val_accuracy: 0.7000\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 0.6923 - accuracy: 0.5333 - val_loss: 0.6858 - val_accuracy: 0.7000\n",
      "Epoch 4/15\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 0.6924 - accuracy: 0.5333 - val_loss: 0.6862 - val_accuracy: 0.7000\n",
      "Epoch 5/15\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 0.6928 - accuracy: 0.5333 - val_loss: 0.6826 - val_accuracy: 0.7000\n",
      "Epoch 6/15\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.6913 - accuracy: 0.5333 - val_loss: 0.6846 - val_accuracy: 0.7000\n",
      "Epoch 7/15\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 0.6918 - accuracy: 0.5333 - val_loss: 0.6835 - val_accuracy: 0.7000\n",
      "Epoch 8/15\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 0.6897 - accuracy: 0.5333 - val_loss: 0.6810 - val_accuracy: 0.7000\n",
      "Epoch 9/15\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 0.6890 - accuracy: 0.5333 - val_loss: 0.6802 - val_accuracy: 0.7000\n",
      "Epoch 10/15\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 0.6861 - accuracy: 0.5333 - val_loss: 0.6754 - val_accuracy: 0.7000\n",
      "Epoch 11/15\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.6808 - accuracy: 0.5500 - val_loss: 0.6688 - val_accuracy: 0.7333\n",
      "Epoch 12/15\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 0.6723 - accuracy: 0.6667 - val_loss: 0.6548 - val_accuracy: 0.8333\n",
      "Epoch 13/15\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 0.6525 - accuracy: 0.7000 - val_loss: 0.6661 - val_accuracy: 0.6667\n",
      "Epoch 14/15\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 0.6664 - accuracy: 0.6000 - val_loss: 0.6763 - val_accuracy: 0.6333\n",
      "Epoch 15/15\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 0.6089 - accuracy: 0.7667 - val_loss: 0.6004 - val_accuracy: 0.8333\n",
      "Saved model to disk\n",
      ">#1 validation accuracy: 82.609\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 2)                 264       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 6         \n",
      "=================================================================\n",
      "Total params: 276\n",
      "Trainable params: 276\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 60 samples, validate on 30 samples\n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 0.6874 - accuracy: 0.6167 - val_loss: 0.6829 - val_accuracy: 0.4667\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 2s 40ms/step - loss: 0.6811 - accuracy: 0.5500 - val_loss: 0.6791 - val_accuracy: 0.6667\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 2s 40ms/step - loss: 0.6667 - accuracy: 0.6333 - val_loss: 0.6751 - val_accuracy: 0.6000\n",
      "Epoch 4/15\n",
      "60/60 [==============================] - 2s 40ms/step - loss: 0.6786 - accuracy: 0.6333 - val_loss: 0.6704 - val_accuracy: 0.6000\n",
      "Epoch 5/15\n",
      "60/60 [==============================] - 2s 40ms/step - loss: 0.6943 - accuracy: 0.4500 - val_loss: 0.6631 - val_accuracy: 0.7667\n",
      "Epoch 6/15\n",
      "60/60 [==============================] - 2s 40ms/step - loss: 0.6716 - accuracy: 0.5333 - val_loss: 0.6604 - val_accuracy: 0.7667\n",
      "Epoch 7/15\n",
      "60/60 [==============================] - 2s 40ms/step - loss: 0.6670 - accuracy: 0.5667 - val_loss: 0.6571 - val_accuracy: 0.8000\n",
      "Epoch 8/15\n",
      "60/60 [==============================] - 2s 41ms/step - loss: 0.6862 - accuracy: 0.5500 - val_loss: 0.6605 - val_accuracy: 0.7000\n",
      "Epoch 9/15\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.6742 - accuracy: 0.5667 - val_loss: 0.6419 - val_accuracy: 0.8000\n",
      "Epoch 10/15\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 0.6630 - accuracy: 0.6333 - val_loss: 0.6406 - val_accuracy: 0.8333\n",
      "Epoch 11/15\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 0.6602 - accuracy: 0.5333 - val_loss: 0.6352 - val_accuracy: 0.8333\n",
      "Epoch 12/15\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.6313 - accuracy: 0.6833 - val_loss: 0.6289 - val_accuracy: 0.8333\n",
      "Epoch 13/15\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 0.6480 - accuracy: 0.6333 - val_loss: 0.6263 - val_accuracy: 0.8333\n",
      "Epoch 14/15\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 0.6313 - accuracy: 0.6833 - val_loss: 0.6213 - val_accuracy: 0.8667\n",
      "Epoch 15/15\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.6346 - accuracy: 0.6667 - val_loss: 0.6119 - val_accuracy: 0.9000\n",
      "Saved model to disk\n",
      ">#2 validation accuracy: 91.304\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 2)                 264       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 6         \n",
      "=================================================================\n",
      "Total params: 276\n",
      "Trainable params: 276\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 60 samples, validate on 30 samples\n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 0.6735 - accuracy: 0.7167 - val_loss: 0.6845 - val_accuracy: 0.8333\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 3s 44ms/step - loss: 0.6702 - accuracy: 0.7333 - val_loss: 0.6746 - val_accuracy: 0.8333\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 3s 42ms/step - loss: 0.6665 - accuracy: 0.7000 - val_loss: 0.6552 - val_accuracy: 0.9000\n",
      "Epoch 4/15\n",
      "60/60 [==============================] - 3s 44ms/step - loss: 0.6435 - accuracy: 0.8167 - val_loss: 0.6381 - val_accuracy: 0.9000\n",
      "Epoch 5/15\n",
      "60/60 [==============================] - 3s 43ms/step - loss: 0.6194 - accuracy: 0.8167 - val_loss: 0.6267 - val_accuracy: 0.9333\n",
      "Epoch 6/15\n",
      "60/60 [==============================] - 3s 44ms/step - loss: 0.5922 - accuracy: 0.8333 - val_loss: 0.5935 - val_accuracy: 0.9333\n",
      "Epoch 7/15\n",
      "60/60 [==============================] - 3s 43ms/step - loss: 0.5386 - accuracy: 0.8667 - val_loss: 0.5680 - val_accuracy: 0.9333\n",
      "Epoch 8/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 2s 40ms/step - loss: 0.4981 - accuracy: 0.8500 - val_loss: 0.5385 - val_accuracy: 0.9333\n",
      "Epoch 9/15\n",
      "60/60 [==============================] - 2s 40ms/step - loss: 0.4819 - accuracy: 0.8333 - val_loss: 0.5111 - val_accuracy: 0.9333\n",
      "Epoch 10/15\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.4832 - accuracy: 0.8167 - val_loss: 0.4788 - val_accuracy: 0.9333\n",
      "Epoch 11/15\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.4010 - accuracy: 0.8333 - val_loss: 0.4346 - val_accuracy: 0.9333\n",
      "Epoch 12/15\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 0.3380 - accuracy: 0.9333 - val_loss: 0.3809 - val_accuracy: 0.9667\n",
      "Epoch 13/15\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.3669 - accuracy: 0.8500 - val_loss: 0.3509 - val_accuracy: 0.9667\n",
      "Epoch 14/15\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.3454 - accuracy: 0.8167 - val_loss: 0.3217 - val_accuracy: 0.9333\n",
      "Epoch 15/15\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.3226 - accuracy: 0.8833 - val_loss: 0.3012 - val_accuracy: 0.9333\n",
      "Saved model to disk\n",
      ">#3 validation accuracy: 100.000\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 2)                 264       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 6         \n",
      "=================================================================\n",
      "Total params: 276\n",
      "Trainable params: 276\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 60 samples, validate on 30 samples\n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 4s 71ms/step - loss: 0.7706 - accuracy: 0.4167 - val_loss: 0.7372 - val_accuracy: 0.2667\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 4s 59ms/step - loss: 0.7523 - accuracy: 0.2500 - val_loss: 0.7149 - val_accuracy: 0.4333\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 3s 42ms/step - loss: 0.7199 - accuracy: 0.3667 - val_loss: 0.7006 - val_accuracy: 0.4667\n",
      "Epoch 4/15\n",
      "60/60 [==============================] - 3s 49ms/step - loss: 0.7074 - accuracy: 0.3500 - val_loss: 0.6915 - val_accuracy: 0.6000\n",
      "Epoch 5/15\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.7019 - accuracy: 0.4667 - val_loss: 0.6868 - val_accuracy: 0.6333\n",
      "Epoch 6/15\n",
      "60/60 [==============================] - 2s 36ms/step - loss: 0.6947 - accuracy: 0.5167 - val_loss: 0.6863 - val_accuracy: 0.6333\n",
      "Epoch 7/15\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 0.6929 - accuracy: 0.5333 - val_loss: 0.6833 - val_accuracy: 0.6667\n",
      "Epoch 8/15\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 0.6939 - accuracy: 0.5333 - val_loss: 0.6810 - val_accuracy: 0.7000\n",
      "Epoch 9/15\n",
      "60/60 [==============================] - 2s 36ms/step - loss: 0.6975 - accuracy: 0.4833 - val_loss: 0.6815 - val_accuracy: 0.7000\n",
      "Epoch 10/15\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 0.6929 - accuracy: 0.5167 - val_loss: 0.6793 - val_accuracy: 0.7333\n",
      "Epoch 11/15\n",
      "21/60 [=========>....................] - ETA: 1s - loss: 0.7036 - accuracy: 0.4286"
     ]
    }
   ],
   "source": [
    "run_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(train_loss_history['0'], color='blue', label='train')\n",
    "pyplot.plot(val_loss_history['0'], color='orange', label='validation')\n",
    "pyplot.title('LSTM model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "#pyplot.show()\n",
    "\n",
    "pyplot.savefig('model-train-vs-validation-loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(train_accuracy_history['0'], color='blue', label='train')\n",
    "pyplot.plot(val_accuracy_history['0'], color='orange', label='validation')\n",
    "pyplot.title('LSTM model train vs validation accuracy')\n",
    "pyplot.ylabel('accuracy')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "#pyplot.show()\n",
    "\n",
    "pyplot.savefig('model-train-vs-validation-accuracy.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openpose-jupyter-data-exploration",
   "language": "python",
   "name": "openpose-jupyter-data-exploration"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

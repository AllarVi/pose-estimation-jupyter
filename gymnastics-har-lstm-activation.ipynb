{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "\n",
    "\n",
    "from numpy import dstack\n",
    "\n",
    "import copy\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from path import Path\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Bidirectional\n",
    "\n",
    "from keras.models import model_from_json\n",
    "\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import random\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import pyplot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# load json and create model\n",
    "json_file = open('model-0.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model-0.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padded samples len: 113\n"
     ]
    }
   ],
   "source": [
    "def pad_with_zeros(orig_ndarray, desired_rows_count):\n",
    "    (frames, features) = orig_ndarray.shape\n",
    "\n",
    "    sample_df = pd.DataFrame(data=orig_ndarray,\n",
    "                             index=np.arange(frames),\n",
    "                             columns=np.arange(features))\n",
    "\n",
    "    zeros_df = pd.DataFrame(0,\n",
    "                            index=np.arange(desired_rows_count),\n",
    "                            columns=np.arange(features),\n",
    "                            dtype='float')\n",
    "\n",
    "    for i in range(features):\n",
    "        zeros_df[i] = sample_df[i].astype(float)\n",
    "    \n",
    "    \n",
    "    padded_df = zeros_df.fillna(0)\n",
    "\n",
    "    return padded_df.to_numpy()\n",
    "\n",
    "def filter_active_keypoints(frame_df):\n",
    "    #active_keypoints = [0, 1, 8, 2, 3, 4, 5, 6, 7] # trunk\n",
    "    \n",
    "    active_keypoints = [0, 1, 8, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14]\n",
    "    \n",
    "    filtered_df  = frame_df[frame_df.index.isin(active_keypoints)]\n",
    "    #filtered_df = frame_df\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def get_frame_data(filepath):\n",
    "    frame_data = pd.read_csv(filepath)\n",
    "    \n",
    "    x_data = filter_active_keypoints(frame_data.iloc[:, 0])\n",
    "    y_data = filter_active_keypoints(frame_data.iloc[:, 1])\n",
    "    \n",
    "    #print(f\"x_data shape: {x_data.shape}\")\n",
    "    #print(f\"y_data shape: {y_data.shape}\")\n",
    "        \n",
    "    h_stacked = np.hstack((x_data, y_data))\n",
    "    #h_stacked = np.hstack((y_data))\n",
    "    \n",
    "    return h_stacked\n",
    "\n",
    "def get_frame_file_path(frame_file_path_template, frame_idx):\n",
    "    frame_file_path = frame_file_path_template.replace(\"[frame_idx]\", str(frame_idx))\n",
    "    return frame_file_path\n",
    "\n",
    "def get_frames_count(root_path, sample_dir_name):\n",
    "    return len([Path(f).abspath() for f in glob(f\"{root_path}/{sample_dir_name}\" + '/*')])\n",
    "\n",
    "def get_frames(root_path, sample_dir_name):\n",
    "    frames = []\n",
    "    for frame_idx in range(0, get_frames_count(root_path, sample_dir_name)):\n",
    "        frame_file_path_template = f\"{root_path}/{sample_dir_name}/{sample_dir_name}.mov-[frame_idx]-0.csv\"\n",
    "        frame_file_path = get_frame_file_path(frame_file_path_template, frame_idx)\n",
    "        frame_data = get_frame_data(frame_file_path)\n",
    "        \n",
    "        frames.append(frame_data)\n",
    "        \n",
    "    return np.dstack(frames)\n",
    "\n",
    "def get_samples_list(sample_dir_names, root_path):\n",
    "    samples = []\n",
    "    sample_names = []\n",
    "    for sample_dir_name in sample_dir_names:\n",
    "        frames = get_frames(root_path, sample_dir_name)\n",
    "        squeezed = np.squeeze(frames)\n",
    "        axes_swapped = np.swapaxes(squeezed, 0, 1)\n",
    "        samples.append(axes_swapped)\n",
    "        \n",
    "        sample_names.append(sample_dir_name)\n",
    "        \n",
    "    return samples, sample_names\n",
    "\n",
    "root_path = \"/Users/allarviinamae/EduWorkspace/openpose-jupyter-data-exploration/centered-keypoints\"\n",
    "\n",
    "sample_dir_names = [n for n in os.listdir(root_path) if os.path.isdir(f\"{root_path}/{n}\")]\n",
    "\n",
    "samples, sample_names = get_samples_list(sample_dir_names, root_path)\n",
    "\n",
    "def get_padded_samples(samples):\n",
    "    padded_samples_list = []\n",
    "\n",
    "    for idx, sample_ndarray in enumerate(samples):\n",
    "        desired_rows_count = 110\n",
    "\n",
    "        padded_ndarray = pad_with_zeros(sample_ndarray, desired_rows_count)\n",
    "\n",
    "        padded_samples_list = padded_samples_list + [padded_ndarray]\n",
    "        \n",
    "    return padded_samples_list\n",
    "\n",
    "padded_samples_list = get_padded_samples(samples)\n",
    "\n",
    "padded_samples_beefy_list = padded_samples_list\n",
    "\n",
    "print(f\"padded samples len: {len(padded_samples_beefy_list)}\")\n",
    "padded_samples_beefy_ndarray = np.asarray(padded_samples_beefy_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_labels_stacked shape: (1, 1, 113)\n",
      "y_labels_categorical shape: (1, 1, 113, 2)\n",
      "y_labels_squeezed shape (113, 2)\n"
     ]
    }
   ],
   "source": [
    "def get_label(sample_dir_name):\n",
    "    return 0 if sample_dir_name[0] == 'b' else 1\n",
    "\n",
    "def get_y_labels(sample_dir_names):\n",
    "    return [get_label(l) for l in sample_dir_names]\n",
    "\n",
    "y_labels = get_y_labels(sample_dir_names) # classifier labels, where 0 = backflip and 1 = flack\n",
    "\n",
    "y_labels_stacked = np.dstack(y_labels)\n",
    "print(f\"y_labels_stacked shape: {y_labels_stacked.shape}\")\n",
    "\n",
    "y_labels_categorical = to_categorical(y_labels_stacked) \n",
    "print(f\"y_labels_categorical shape: {y_labels_categorical.shape}\")\n",
    "\n",
    "y_labels_squeezed = np.squeeze(y_labels_categorical)\n",
    "print(f\"y_labels_squeezed shape {y_labels_squeezed.shape}\")\n",
    "\n",
    "(y_rows, y_cols) = y_labels_squeezed.shape\n",
    "y_labels_list = [[y_labels_squeezed[i, 0], y_labels_squeezed[i, 1]] for i in range(y_rows)]\n",
    "\n",
    "y_labels_beefy_ndarray = np.asarray(y_labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113, 110, 30)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_samples_beefy_ndarray.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name=backflip-40-margus, X=0, Predicted=0, Actual=0, same=True\n",
      "Name=flack-31-rasmus, X=1, Predicted=1, Actual=1, same=True\n",
      "Name=flack-19-rasmus, X=2, Predicted=1, Actual=1, same=True\n",
      "Name=flack-59-martin, X=3, Predicted=1, Actual=1, same=True\n",
      "Name=backflip-66-allar, X=4, Predicted=0, Actual=0, same=True\n",
      "Name=flack-55-martin, X=5, Predicted=1, Actual=1, same=True\n",
      "Name=flack-68-rasmus, X=6, Predicted=1, Actual=1, same=True\n",
      "Name=backflip-23-tiit, X=7, Predicted=0, Actual=0, same=True\n",
      "Name=flack-7-hendrik, X=8, Predicted=1, Actual=1, same=True\n",
      "Name=flack-4-martin, X=9, Predicted=1, Actual=1, same=True\n",
      "Name=flack-15-rasmus, X=10, Predicted=1, Actual=1, same=True\n",
      "Name=flack-36-hendrik, X=11, Predicted=1, Actual=1, same=True\n",
      "Name=backflip-64-allar, X=12, Predicted=0, Actual=0, same=True\n",
      "Name=backflip-6-rasmus, X=13, Predicted=0, Actual=0, same=True\n",
      "Name=flack-82-martin, X=14, Predicted=1, Actual=1, same=True\n",
      "Name=flack-35-margus, X=15, Predicted=1, Actual=1, same=True\n",
      "Name=backflip-38-mario, X=16, Predicted=0, Actual=0, same=True\n",
      "Name=flack-39-margus, X=17, Predicted=1, Actual=1, same=True\n",
      "Name=backflip-32-hendrik, X=18, Predicted=0, Actual=0, same=True\n",
      "Name=backflip-20-martin, X=19, Predicted=0, Actual=0, same=True\n",
      "Name=flack-25-margus, X=20, Predicted=1, Actual=1, same=True\n",
      "Name=flack-29-julia, X=21, Predicted=1, Actual=1, same=True\n",
      "Name=backflip-8-rasmus, X=22, Predicted=0, Actual=0, same=True\n",
      "Name=flack-80-martin, X=23, Predicted=1, Actual=1, same=True\n",
      "Name=backflip-4-rasmus, X=24, Predicted=0, Actual=0, same=True\n",
      "Name=backflip-54-rasmus, X=25, Predicted=0, Actual=0, same=True\n",
      "Name=backflip-48-joosep, X=26, Predicted=0, Actual=0, same=True\n",
      "Name=backflip-47-dagne, X=27, Predicted=0, Actual=0, same=True\n",
      "Name=flack-33-rasmus, X=28, Predicted=1, Actual=1, same=True\n",
      "Name=flack-61-martin, X=29, Predicted=1, Actual=1, same=True\n",
      "Name=flack-17-rasmus, X=30, Predicted=1, Actual=1, same=True\n",
      "Name=flack-57-martin, X=31, Predicted=1, Actual=1, same=True\n",
      "Name=flack-6-hendrik, X=32, Predicted=1, Actual=1, same=True\n",
      "Name=flack-37-hendrik, X=33, Predicted=1, Actual=1, same=True\n",
      "Name=flack-66-rasmus, X=34, Predicted=1, Actual=1, same=True\n",
      "Name=backflip-65-allar, X=35, Predicted=0, Actual=0, same=True\n",
      "Name=flack-84-martin, X=36, Predicted=1, Actual=1, same=True\n",
      "Name=backflip-31-hendrik, X=37, Predicted=0, Actual=0, same=True\n",
      "Name=flack-62-rasmus, X=38, Predicted=1, Actual=1, same=True\n",
      "Name=flack-50-kristiin, X=39, Predicted=1, Actual=1, same=True\n",
      "Name=flack-70-rasmus, X=40, Predicted=1, Actual=1, same=True\n",
      "Name=backflip-58-margus, X=41, Predicted=0, Actual=0, same=True\n",
      "Name=backflip-25-tiit, X=42, Predicted=0, Actual=0, same=True\n",
      "Name=backflip-24-tiit, X=43, Predicted=0, Actual=0, same=True\n",
      "Name=backflip-63-allar, X=44, Predicted=0, Actual=0, same=True\n",
      "Name=backflip-46-dagne, X=45, Predicted=1, Actual=0, same=False\n",
      "Name=backflip-56-margus, X=46, Predicted=0, Actual=0, same=True\n",
      "Name=backflip-39-margus, X=47, Predicted=0, Actual=0, same=True\n",
      "Name=flack-79-martin, X=48, Predicted=1, Actual=1, same=True\n",
      "Name=flack-47-kristiin, X=49, Predicted=1, Actual=1, same=True\n",
      "Name=flack-46-kristiin, X=50, Predicted=1, Actual=1, same=True\n",
      "Name=backflip-50-joosep, X=51, Predicted=0, Actual=0, same=True\n",
      "Name=flack-28-julia, X=52, Predicted=1, Actual=1, same=True\n",
      "Name=flack-40-margus, X=53, Predicted=1, Actual=1, same=True\n",
      "Name=backflip-30-hendrik, X=54, Predicted=0, Actual=0, same=True\n",
      "Name=backflip-52-rasmus, X=55, Predicted=0, Actual=0, same=True\n",
      "Name=flack-9-hendrik, X=56, Predicted=1, Actual=1, same=True\n",
      "Name=flack-38-hendrik, X=57, Predicted=1, Actual=1, same=True\n",
      "Name=flack-83-martin, X=58, Predicted=1, Actual=1, same=True\n",
      "Name=backflip-7-rasmus, X=59, Predicted=0, Actual=0, same=True\n",
      "Name=flack-26-margus, X=60, Predicted=1, Actual=1, same=True\n",
      "Name=flack-58-martin, X=61, Predicted=1, Actual=1, same=True\n",
      "Name=backflip-27-tiit, X=62, Predicted=0, Actual=0, same=True\n",
      "Name=flack-65-rasmus, X=63, Predicted=1, Actual=1, same=True\n",
      "Name=backflip-43-kristjan, X=64, Predicted=0, Actual=0, same=True\n",
      "Name=flack-5-martin, X=65, Predicted=1, Actual=1, same=True\n",
      "Name=flack-69-rasmus, X=66, Predicted=1, Actual=1, same=True\n",
      "Name=backflip-61-hendrik, X=67, Predicted=0, Actual=0, same=True\n",
      "Name=flack-30-rasmus, X=68, Predicted=1, Actual=1, same=True\n",
      "Name=backflip-33-mario, X=69, Predicted=0, Actual=0, same=True\n",
      "Name=flack-56-martin, X=70, Predicted=1, Actual=1, same=True\n",
      "Name=flack-16-rasmus, X=71, Predicted=1, Actual=1, same=True\n",
      "Name=backflip-37-mario, X=72, Predicted=0, Actual=0, same=True\n",
      "Name=flack-67-rasmus, X=73, Predicted=1, Actual=1, same=True\n",
      "Name=flack-20-allar, X=74, Predicted=1, Actual=1, same=True\n",
      "Name=flack-32-rasmus, X=75, Predicted=1, Actual=1, same=True\n",
      "Name=backflip-60-hendrik, X=76, Predicted=0, Actual=0, same=True\n",
      "Name=flack-60-martin, X=77, Predicted=1, Actual=1, same=True\n",
      "Name=backflip-2-allar, X=78, Predicted=0, Actual=0, same=True\n",
      "Name=backflip-26-tiit, X=79, Predicted=0, Actual=0, same=True\n",
      "Name=flack-49-kristiin, X=80, Predicted=1, Actual=1, same=True\n",
      "Name=flack-48-kristiin, X=81, Predicted=1, Actual=1, same=True\n",
      "Name=backflip-49-joosep, X=82, Predicted=0, Actual=0, same=True\n",
      "Name=backflip-19-martin, X=83, Predicted=1, Actual=0, same=False\n",
      "Name=backflip-35-mario, X=84, Predicted=0, Actual=0, same=True\n",
      "Name=backflip-55-rasmus, X=85, Predicted=0, Actual=0, same=True\n",
      "Name=backflip-5-rasmus, X=86, Predicted=0, Actual=0, same=True\n",
      "Name=flack-81-martin, X=87, Predicted=1, Actual=1, same=True\n",
      "Name=flack-27-julia, X=88, Predicted=1, Actual=1, same=True\n",
      "Name=flack-44-kristiin, X=89, Predicted=1, Actual=1, same=True\n",
      "Name=flack-45-kristiin, X=90, Predicted=1, Actual=1, same=True\n",
      "Name=backflip-59-margus, X=91, Predicted=0, Actual=0, same=True\n",
      "Name=flack-63-rasmus, X=92, Predicted=1, Actual=1, same=True\n",
      "Name=backflip-10-hendrik, X=93, Predicted=0, Actual=0, same=True\n",
      "Name=flack-71-rasmus, X=94, Predicted=1, Actual=1, same=True\n",
      "Name=flack-3-martin, X=95, Predicted=1, Actual=1, same=True\n",
      "Name=flack-24-belinda, X=96, Predicted=1, Actual=1, same=True\n",
      "Name=flack-12-rasmus, X=97, Predicted=1, Actual=1, same=True\n",
      "Name=backflip-51-rasmus, X=98, Predicted=0, Actual=0, same=True\n",
      "Name=backflip-1-allar, X=99, Predicted=0, Actual=0, same=True\n",
      "Name=backflip-53-rasmus, X=100, Predicted=0, Actual=0, same=True\n",
      "Name=backflip-34-mario, X=101, Predicted=0, Actual=0, same=True\n",
      "Name=flack-34-rasmus, X=102, Predicted=1, Actual=1, same=True\n",
      "Name=flack-21-allar, X=103, Predicted=1, Actual=1, same=True\n",
      "Name=backflip-36-mario, X=104, Predicted=0, Actual=0, same=True\n",
      "Name=backflip-57-margus, X=105, Predicted=0, Actual=0, same=True\n",
      "Name=flack-78-martin, X=106, Predicted=1, Actual=1, same=True\n",
      "Name=backflip-44-kristjan, X=107, Predicted=1, Actual=0, same=False\n",
      "Name=backflip-45-kristjan, X=108, Predicted=0, Actual=0, same=True\n",
      "Name=flack-1-martin, X=109, Predicted=1, Actual=1, same=True\n",
      "Name=flack-10-rasmus, X=110, Predicted=1, Actual=1, same=True\n",
      "Name=backflip-3-allar, X=111, Predicted=0, Actual=0, same=True\n",
      "Name=backflip-9-hendrik, X=112, Predicted=0, Actual=0, same=True\n"
     ]
    }
   ],
   "source": [
    "ynew = loaded_model.predict_classes(padded_samples_beefy_ndarray)\n",
    "# show the inputs and predicted outputs\n",
    "for i in range(len(padded_samples_beefy_ndarray)):\n",
    "    pred_y = ynew[i]\n",
    "    actual_y = y_labels[i]\n",
    "    \n",
    "    same = False\n",
    "    if pred_y == actual_y:\n",
    "        same = True\n",
    "    \n",
    "    print(\"Name=%s, X=%s, Predicted=%s, Actual=%s, same=%s\" % (sample_names[i], i, pred_y, actual_y, same))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.recurrent.LSTM object at 0x1398cb278>\n",
      "<tensorflow.python.keras.backend.EagerExecutionFunction object at 0x13cac4438>\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "\n",
    "# 3rd layer is LSTM layer with output shape (Batch_Size, 512)\n",
    "lstm = loaded_model.layers[0]\n",
    "\n",
    "print(lstm)\n",
    "\n",
    "# Get output from intermediate layer to visualize activations\n",
    "attn_func = K.function(inputs = [lstm.input, K.learning_phase()],\n",
    "                       outputs = [lstm.output])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get html element\n",
    "def cstr(s, color='black'):\n",
    "    if s == ' ':\n",
    "        return \"<text style=color:#000;padding-left:10px;background-color:{}> </text>\".format(color, s)\n",
    "    else:\n",
    "        return \"<text style=color:#000;background-color:{}>{} </text>\".format(color, s)\n",
    "\n",
    "# print html\n",
    "def print_color(t):\n",
    "    display(html_print(''.join([cstr(ti, color=ci) for ti,ci in t])))\n",
    "\n",
    "# get appropriate color for value\n",
    "def get_clr(value):\n",
    "    colors = ['#85c2e1', '#89c4e2', '#95cae5', '#99cce6', '#a1d0e8'\n",
    "        '#b2d9ec', '#baddee', '#c2e1f0', '#eff7fb', '#f9e8e8',\n",
    "        '#f9e8e8', '#f9d4d4', '#f9bdbd', '#f8a8a8', '#f68f8f',\n",
    "        '#f47676', '#f45f5f', '#f34343', '#f33b3b', '#f42e2e']\n",
    "    value = int((value * 100) / 5)\n",
    "    return colors[value]\n",
    "\n",
    "# sigmoid function\n",
    "def sigmoid(x):\n",
    "    z = 1/(1 + np.exp(-x)) \n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing activations for flack-17-rasmus\n",
      "\"-38 26 9 -100 -227 38 -115 -233 0 -20 -12 3 12 3 15 -262 -218 -215 -194 -221 -230 -209 -227 0 0 165 336 -0 165 350\"\n",
      "\"-35 29 24 -112 -229 35 -115 -235 0 -15 -9 3 9 3 9 -262 -215 -215 -191 -209 -230 -194 -212 -0 -0 168 336 -0 165 350\"\n",
      "\"-34 28 17 -103 -226 37 -114 -234 0 -18 -12 3 9 3 11 -262 -216 -215 -189 -206 -229 -197 -209 -0 0 167 336 -0 165 350\"\n",
      "\"-30 28 21 -102 -223 38 -110 -234 0 -17 -12 3 7 3 9 -262 -215 -215 -181 -187 -227 -185 -189 -0 0 167 335 -0 165 350\"\n",
      "\"-27 29 22 -97 -216 40 -104 -230 -0 -17 -13 3 5 2 9 -262 -215 -214 -173 -166 -223 -177 -167 0 1 166 335 0 165 350\"\n",
      "\"-26 32 27 -95 -205 40 -97 -223 0 -13 -11 3 4 1 9 -262 -215 -213 -165 -144 -220 -168 -144 0 1 166 335 0 166 350\"\n",
      "\"-25 37 31 -90 -194 40 -92 -213 0 -11 -12 3 3 0 9 -262 -215 -213 -156 -123 -218 -158 -122 0 1 167 335 0 167 351\"\n",
      "\"-24 41 38 -79 -180 38 -84 -201 0 -6 -10 3 2 -0 9 -262 -215 -214 -144 -103 -217 -149 -101 1 0 169 335 1 169 352\"\n",
      "\"-24 43 44 -71 -159 36 -77 -186 0 -4 -10 3 1 -0 8 -261 -215 -215 -131 -86 -216 -136 -83 2 1 170 335 3 170 353\"\n",
      "\"-24 44 49 -56 -140 35 -66 -170 0 0 -8 3 0 -0 8 -260 -215 -215 -118 -70 -215 -128 -66 2 1 171 335 4 171 353\"\n",
      "\"-24 45 50 -43 -101 35 -57 -153 0 1 -8 3 0 -0 7 -259 -215 -215 -107 -58 -214 -119 -47 2 2 171 336 4 171 353\"\n",
      "\"-24 45 49 -29 -75 36 -46 -136 0 2 -6 3 0 -1 7 -259 -214 -215 -98 -45 -213 -110 -28 2 2 171 337 3 171 353\"\n",
      "\"-25 45 48 -24 -49 35 -36 -117 1 4 -4 2 0 -2 6 -259 -213 -215 -95 -36 -212 -101 -12 3 3 171 340 3 171 353\"\n",
      "\"-27 44 47 -19 -26 35 -23 -93 2 8 -2 1 1 -2 6 -259 -212 -214 -94 -24 -212 -94 1 3 3 171 342 3 171 353\"\n",
      "\"-30 44 48 -7 8 33 -10 -69 6 15 -1 0 2 -1 6 -259 -212 -213 -95 -14 -212 -92 11 3 2 171 344 4 172 353\"\n",
      "\"-34 44 50 12 51 30 5 -42 8 19 0 0 4 0 6 -259 -212 -213 -96 -7 -212 -91 18 2 -0 170 343 4 171 353\"\n",
      "\"-38 43 51 31 73 28 16 -15 10 22 0 1 4 1 6 -258 -212 -214 -96 -4 -212 -92 21 3 -1 168 342 7 171 353\"\n",
      "\"-41 39 49 47 83 27 31 15 6 14 1 1 4 2 6 -257 -212 -215 -100 -2 -212 -93 21 9 6 168 343 12 170 353\"\n",
      "\"-43 33 40 57 89 27 41 42 5 8 1 2 7 3 6 -256 -213 -215 -105 -1 -213 -97 16 13 12 167 344 16 170 353\"\n",
      "\"-45 28 30 64 91 27 55 69 7 1 2 2 14 3 7 -256 -214 -215 -113 -1 -214 -104 9 13 14 167 345 15 169 353\"\n",
      "\"-47 26 24 68 93 26 64 93 14 3 2 3 22 5 8 -254 -215 -215 -117 -0 -215 -112 -1 8 9 165 344 10 168 352\"\n",
      "\"-52 25 21 70 94 25 74 118 21 8 3 3 27 10 10 -252 -215 -215 -103 -0 -216 -118 -11 5 5 165 344 6 168 351\"\n",
      "\"-58 25 22 74 96 23 82 140 27 16 3 3 32 17 11 -248 -216 -215 -99 -6 -218 -123 -26 3 4 165 343 3 168 350\"\n",
      "\"-64 22 18 80 103 21 90 162 34 25 8 4 39 22 12 -245 -216 -215 -99 -18 -220 -132 -42 0 1 164 341 0 166 350\"\n",
      "\"-68 18 15 86 116 17 101 178 42 31 14 5 49 25 11 -241 -216 -215 -116 -33 -220 -140 -62 -2 -1 163 339 -2 165 350\"\n",
      "\"-72 13 9 90 129 13 109 193 49 35 21 6 60 27 10 -238 -215 -214 -127 -50 -219 -151 -80 -4 -3 159 337 -5 163 350\"\n",
      "\"-75 8 6 92 139 8 117 204 57 41 24 7 70 30 9 -235 -214 -213 -134 -64 -217 -159 -100 -5 -3 156 336 -6 162 349\"\n",
      "\"-81 5 4 98 147 4 120 219 65 47 26 6 81 37 11 -227 -213 -211 -147 -79 -215 -166 -119 -6 -3 155 335 -9 161 349\"\n",
      "\"-86 2 1 107 179 2 121 227 77 58 28 5 89 43 15 -219 -208 -208 -157 -108 -210 -174 -139 -6 -3 155 334 -8 160 348\"\n",
      "\"-90 1 -3 109 186 1 122 234 85 66 29 3 102 47 20 -207 -200 -199 -162 -125 -202 -181 -156 -5 -3 156 334 -8 160 348\"\n",
      "\"-91 0 -9 112 191 2 122 236 93 75 31 4 111 47 24 -197 -189 -186 -168 -139 -193 -187 -173 -2 1 156 333 -4 159 347\"\n",
      "\"-91 0 -14 105 169 2 122 238 100 82 33 9 120 47 30 -182 -178 -172 -160 -139 -182 -188 -186 -0 3 157 332 -2 157 347\"\n",
      "\"-91 0 -15 100 143 4 121 216 109 91 35 16 128 47 37 -167 -164 -158 -127 -113 -170 -187 -184 2 6 155 331 0 153 347\"\n",
      "\"-91 1 -14 87 103 6 124 215 117 99 36 25 135 46 45 -150 -151 -146 -74 -66 -155 -185 -192 5 9 153 330 3 150 347\"\n",
      "\"-91 2 -10 80 57 8 125 214 122 103 34 34 142 44 55 -133 -136 -132 -25 -5 -139 -181 -198 11 15 153 330 9 148 347\"\n",
      "\"-89 6 -6 77 35 14 128 234 128 108 31 43 149 44 64 -117 -122 -117 -1 25 -126 -175 -215 18 21 155 330 17 151 346\"\n",
      "\"-87 10 -2 75 23 19 131 234 135 114 29 50 156 45 73 -100 -106 -101 11 41 -111 -168 -216 25 27 156 329 23 153 344\"\n",
      "\"-82 16 1 74 17 26 135 235 142 121 26 52 164 45 80 -84 -90 -85 17 48 -98 -158 -212 34 37 157 328 32 158 343\"\n",
      "\"-78 20 3 74 15 27 139 229 148 130 25 53 168 43 87 -70 -78 -72 21 52 -82 -145 -197 46 50 159 328 43 161 344\"\n",
      "\"-74 24 8 74 13 30 140 230 154 137 23 53 171 37 93 -57 -62 -56 22 54 -67 -129 -178 58 61 162 329 56 165 347\"\n",
      "\"-71 26 14 98 24 32 143 233 161 147 22 53 172 33 94 -45 -49 -43 -16 64 -52 -113 -149 70 72 166 331 70 171 350\"\n",
      "\"-69 29 20 117 41 38 151 250 164 151 18 53 172 29 94 -36 -36 -32 -28 78 -38 -93 -124 81 82 171 334 82 177 352\"\n",
      "\"-66 32 24 134 62 43 160 242 166 157 13 53 172 27 94 -29 -27 -26 -27 93 -28 -69 -99 93 94 176 336 94 182 353\"\n",
      "\"-60 39 27 124 72 48 170 255 167 159 7 53 175 24 93 -26 -19 -17 20 101 -20 -38 -61 105 106 180 337 105 184 353\"\n",
      "\"-52 46 33 119 77 57 179 264 167 157 4 52 178 20 92 -26 -11 -9 44 105 -13 -7 -15 115 115 182 338 116 186 353\"\n",
      "\"-40 57 42 117 80 67 186 289 166 153 2 51 179 16 91 -29 -5 -2 56 107 -7 23 44 127 126 184 341 128 187 354\"\n",
      "\"-26 68 55 116 81 81 191 288 161 145 -0 49 175 13 90 -36 -2 1 62 108 -4 51 100 138 134 186 343 143 189 355\"\n",
      "\"-9 82 66 115 82 97 186 271 154 137 -5 48 170 11 89 -48 -2 1 65 108 -3 75 149 151 143 187 344 156 192 356\"\n",
      "\"15 98 80 115 82 119 179 238 146 127 -9 47 163 9 88 -61 -2 -0 66 109 -3 97 195 159 148 188 344 165 196 355\"\n",
      "\"42 119 96 115 82 141 164 184 149 126 -12 47 169 8 86 -73 -3 -2 67 109 -2 109 221 161 148 188 342 166 199 354\"\n",
      "\"77 139 117 115 82 164 149 127 155 131 -10 47 176 14 85 -82 -2 -3 67 109 1 116 228 159 146 188 341 166 204 353\"\n",
      "\"111 159 137 108 56 184 132 63 162 137 -7 47 184 19 83 -88 -1 -2 70 122 3 109 203 159 144 188 340 166 207 353\"\n",
      "\"146 177 155 105 22 203 123 20 163 140 -6 47 185 18 83 -91 0 -1 62 109 5 89 150 161 149 188 341 171 204 353\"\n",
      "\"179 195 173 99 -7 220 113 -4 165 143 -6 47 186 14 83 -90 0 -0 52 72 4 58 78 164 155 188 341 176 201 353\"\n",
      "\"210 214 190 104 6 238 120 10 167 147 -8 47 186 9 83 -86 0 -1 25 -2 6 24 -1 165 160 188 342 180 196 353\"\n",
      "\"240 232 209 116 46 255 142 52 168 148 -8 48 186 9 83 -80 2 -1 -5 -73 7 -11 -73 166 161 188 343 181 197 353\"\n",
      "\"268 246 223 144 107 272 185 117 168 147 -8 48 186 7 82 -71 4 -2 -40 -128 13 -42 -127 165 158 188 343 180 194 353\"\n",
      "\"291 261 234 183 172 287 229 189 167 144 -8 48 185 11 82 -60 6 -2 -71 -167 17 -71 -160 164 152 187 342 178 193 353\"\n",
      "\"313 280 251 230 242 302 273 260 167 145 -8 47 185 11 81 -49 4 -4 -86 -179 21 -87 -171 158 144 186 340 172 191 352\"\n",
      "\"333 297 269 271 306 319 314 330 166 146 -8 47 184 10 80 -35 4 -5 -96 -174 23 -91 -165 149 133 182 337 161 188 351\"\n",
      "\"355 316 297 307 365 329 349 379 165 148 -6 46 179 6 77 -20 9 -5 -94 -149 28 -62 -131 133 120 176 333 143 179 347\"\n",
      "\"374 333 347 363 420 338 371 414 154 131 1 44 172 11 75 -0 23 12 -68 -100 31 -37 -91 107 99 163 326 111 170 341\"\n",
      "\"393 355 428 450 466 345 383 434 154 134 12 41 166 23 73 19 41 44 -19 -43 29 -24 -50 78 74 149 319 84 154 333\"\n",
      "\"541 364 454 504 509 344 527 580 158 137 28 35 167 41 69 18 50 49 15 17 39 -34 -32 47 47 133 307 52 138 321\"\n",
      "\"820 654 720 761 758 639 808 843 516 508 425 415 517 436 438 -5 21 19 13 22 14 -35 -22 20 17 86 214 24 89 225\"\n",
      "\"955 624 648 684 733 607 963 974 511 504 443 417 512 454 438 3 -8 -21 -5 54 2 -1 21 11 11 68 192 9 69 201\"\n",
      "\"885 616 651 684 718 610 918 917 531 527 462 428 533 473 445 42 -14 1 29 97 -7 43 84 -1 -0 43 165 -3 46 174\"\n",
      "\"608 336 362 422 452 340 673 670 233 225 100 59 231 119 82 114 29 39 85 171 40 99 167 -10 -9 44 210 -13 49 222\"\n",
      "\"465 367 376 447 439 393 545 542 293 283 121 77 288 135 96 156 67 70 137 207 82 136 218 -33 -32 17 182 -37 21 190\"\n",
      "\"389 381 356 408 392 413 477 470 404 358 167 109 401 328 129 179 88 71 153 220 105 166 256 -14 -32 -23 125 -19 7 121\"\n",
      "\"380 379 355 389 364 407 464 457 489 429 224 147 489 524 168 192 97 77 96 232 115 189 282 16 -15 -62 60 16 30 40\"\n",
      "\"374 378 355 370 344 400 455 449 570 515 280 183 574 714 208 200 108 94 116 246 123 207 301 47 10 -102 -10 53 33 -43\"\n",
      "\"365 374 351 359 336 395 449 447 571 555 308 200 574 721 228 212 121 112 136 261 132 221 315 47 27 -122 -45 56 32 -85\"\n",
      "\"351 366 345 351 332 388 451 447 566 549 322 209 569 718 237 222 130 130 218 273 137 228 321 47 34 -131 -62 56 2 -106\"\n",
      "\"342 359 341 352 331 380 456 447 517 497 330 214 536 663 242 231 138 142 223 278 139 232 325 40 31 -137 -72 47 -23 -116\"\n",
      "\"340 356 338 355 331 378 461 448 468 446 345 224 480 550 245 234 144 149 220 278 141 234 326 34 28 -144 -89 34 -72 -122\"\n",
      "\"342 356 335 354 330 379 464 448 419 418 369 240 428 444 251 234 147 152 220 277 143 235 326 27 32 -153 -116 21 -126 -137\"\n",
      "\"341 356 331 354 330 380 463 448 416 419 400 268 407 411 283 233 148 151 217 277 143 235 325 27 34 -158 -152 6 -154 -167\"\n",
      "\"335 355 330 352 331 380 459 448 417 421 427 299 415 441 328 232 145 148 216 277 142 233 324 24 30 -154 -184 -7 -156 -205\"\n",
      "\"333 354 330 352 332 379 454 448 424 426 449 338 425 468 376 227 141 139 212 276 140 232 324 19 21 -145 -212 -24 -151 -235\"\n",
      "\"333 354 330 351 333 379 450 448 432 426 468 379 431 483 403 218 133 128 206 273 138 230 323 4 14 -132 -233 -34 -149 -252\"\n",
      "\"333 355 330 350 333 381 448 447 433 427 483 425 433 495 433 205 127 120 199 268 135 226 320 -2 7 -118 -250 -33 -143 -260\"\n",
      "\"333 356 330 349 333 384 446 447 437 431 495 471 433 506 471 194 121 116 194 264 129 222 317 -9 -0 -104 -258 -24 -134 -263\"\n",
      "\"333 358 333 349 332 388 443 447 438 438 506 519 437 518 519 181 116 109 190 262 122 217 313 -10 -8 -96 -254 -22 -123 -255\"\n",
      "\"335 362 335 351 331 392 437 447 444 444 519 560 443 531 561 172 108 102 187 261 112 213 311 -19 -12 -94 -237 -26 -116 -238\"\n",
      "\"335 369 341 352 330 397 431 446 498 495 612 594 498 542 596 160 99 93 184 259 105 208 308 -1 14 -43 -205 -17 -107 -207\"\n",
      "\"342 375 346 353 329 402 428 444 498 495 619 618 499 550 623 151 91 85 180 254 97 201 305 -2 10 -35 -165 -15 -94 -166\"\n",
      "\"347 381 353 353 327 408 427 439 499 496 625 637 506 555 643 139 82 77 172 246 90 194 297 -2 10 -23 -122 -17 -80 -123\"\n",
      "\"357 388 361 354 325 416 427 433 464 464 550 652 471 558 659 128 74 67 161 237 80 184 288 -32 -28 -55 -84 -41 -69 -85\"\n",
      "\"363 395 370 355 325 423 428 427 480 481 566 659 486 568 670 113 61 56 149 226 68 176 276 -40 -36 -46 -53 -50 -60 -54\"\n",
      "\"370 402 378 357 326 433 430 424 500 497 586 670 502 599 683 101 52 40 136 216 62 165 264 -54 -53 -34 -21 -60 -37 -20\"\n",
      "\"380 409 381 363 328 442 434 422 508 498 604 678 517 622 696 88 40 29 124 201 55 153 248 -59 -56 -21 19 -66 -15 19\"\n",
      "\"389 417 387 370 329 453 440 420 520 500 614 685 536 636 706 78 31 16 109 185 51 140 234 -61 -57 1 60 -68 10 57\"\n",
      "\"399 428 394 377 331 461 444 418 533 513 616 684 550 631 709 65 20 8 97 169 37 126 220 -55 -49 24 98 -61 25 93\"\n",
      "\"406 438 408 381 332 470 448 416 549 535 615 681 566 632 708 54 9 -7 84 153 28 112 204 -48 -41 45 130 -52 46 127\"\n",
      "\"415 448 419 388 335 481 450 416 569 559 616 677 580 636 705 39 -3 -17 70 137 15 99 185 -37 -30 69 160 -40 70 160\"\n",
      "\"427 460 436 396 340 490 457 417 583 575 617 670 594 637 699 27 -14 -30 55 119 5 85 167 -24 -19 90 187 -27 92 189\"\n",
      "\"438 477 452 408 346 503 465 419 596 585 617 667 604 638 696 12 -24 -37 39 100 -10 73 150 -8 -3 109 211 -13 112 213\"\n",
      "\"445 494 473 416 352 515 474 420 603 591 616 668 614 638 697 2 -31 -44 29 83 -20 58 133 9 15 126 227 4 127 229\"\n",
      "\"0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\"\n",
      "\"0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\"\n",
      "\"0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\"\n",
      "\"0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\"\n",
      "\"0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\"\n",
      "\"0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\"\n",
      "\"0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\"\n",
      "\"0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\"\n",
      "\"0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\"\n",
      "\"0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\"\n",
      "\"0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\"\n",
      "Prediction: [[0.42921907 0.57078093]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Arguments and signature arguments do not match. got: 4, expected: 5 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-44a3ffa73715>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0moutput_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_samples_beefy_ndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-67-44a3ffa73715>\u001b[0m in \u001b[0;36mget_predictions\u001b[0;34m(data, sample_names, sample_nr, model)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# LSTM Activations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetOutputLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-67-44a3ffa73715>\u001b[0m in \u001b[0;36mgetOutputLayer\u001b[0;34m(layerNumber, model, X)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetOutputLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayerNumber\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     return K.function([model.layers[0].input, K.learning_phase()],\n\u001b[0;32m----> 3\u001b[0;31m                       [model.layers[layerNumber].output])([X])\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_no\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/envs/openpose-jupyter-data-exploration/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3727\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3729\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/envs/openpose-jupyter-data-exploration/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/envs/openpose-jupyter-data-exploration/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/envs/openpose-jupyter-data-exploration/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/envs/openpose-jupyter-data-exploration/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    525\u001b[0m           \u001b[0;34m\"Arguments and signature arguments do not match. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m           \u001b[0;34m\"got: %s, expected: %s \"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m           (len(args), len(list(self.signature.input_arg))))\n\u001b[0m\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0mfunction_call_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_call_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Arguments and signature arguments do not match. got: 4, expected: 5 "
     ]
    }
   ],
   "source": [
    "def getOutputLayer(layerNumber, model, X):\n",
    "    return K.function([model.layers[0].input, K.learning_phase()],\n",
    "                      [model.layers[layerNumber].output])([X])\n",
    "\n",
    "def visualize(output_values, result_list, cell_no):\n",
    "    print(\"\\nCell Number:\", cell_no, \"\\n\")\n",
    "    text_colours = []\n",
    "    for i in range(len(output_values)):\n",
    "        text = (result_list[i], get_clr(output_values[i][cell_no]))\n",
    "        text_colours.append(text)\n",
    "    print_color(text_colours)\n",
    "\n",
    "# Get Predictions from random sequence\n",
    "def get_predictions(data, sample_names, sample_nr, model):\n",
    "    pattern = data[sample_nr]\n",
    "    sample_name = sample_names[sample_nr]\n",
    "    \n",
    "    print(f\"Analyzing activations for {sample_name}\")\n",
    "    \n",
    "    result_list, output_values = [], []\n",
    "    \n",
    "    pattern_rows, pattern_columns = pattern.shape\n",
    "    for row in pattern:\n",
    "        print(\"\\\"\" + ' '.join([\"{:.0f}\".format(cell) for cell in row]) + \"\\\"\")\n",
    "\n",
    "    (rows_count, features_count) = pattern.shape\n",
    "    pattern = pattern.reshape(1, rows_count, features_count)\n",
    "\n",
    "    #for i in range(1000):\n",
    "\n",
    "        # Prediction\n",
    "    prediction = model.predict(pattern, verbose=0)\n",
    "    print(f\"Prediction: {prediction}\")\n",
    "\n",
    "        # LSTM Activations\n",
    "    output = getOutputLayer(0, model, pattern)\n",
    "    print(output)\n",
    "    \n",
    "    output = sigmoid(output)\n",
    "    output_values.append(output)\n",
    "\n",
    "        # Predicted Character\n",
    "    #    index = np.argmax(prediction)\n",
    "     #   result = int_to_char[index]\n",
    "\n",
    "        # Preparing input for next character\n",
    "      #  seq_in = [int_to_char[value] for value in pattern]\n",
    "       # pattern.append(index)\n",
    "        #pattern = pattern[1:len(pattern)]\n",
    "\n",
    "        # Saving generated characters\n",
    "       # result_list.append(result)\n",
    "    return output_values, result_list\n",
    "\n",
    "output_values, result_list = get_predictions(padded_samples_beefy_ndarray, sample_names, 30, loaded_model)\n",
    "\n",
    "print(output_values)\n",
    "\n",
    "for cell_no in [0, 1]:\n",
    "    visualize(output_values, result_list, cell_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openpose-jupyter-data-exploration",
   "language": "python",
   "name": "openpose-jupyter-data-exploration"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

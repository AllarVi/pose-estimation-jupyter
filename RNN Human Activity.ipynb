{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from path import Path\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_data(filepath):\n",
    "    frame_data = pd.read_csv(filepath)\n",
    "    \n",
    "    x_data = frame_data.iloc[:, 0]\n",
    "    y_data = frame_data.iloc[:, 1]\n",
    "        \n",
    "    h_stacked = np.hstack((x_data, y_data))\n",
    "    \n",
    "    return h_stacked\n",
    "\n",
    "def get_frame_file_path(frame_file_path_template, frame_idx):\n",
    "    frame_file_path = frame_file_path_template.replace(\"[frame_idx]\", str(frame_idx))\n",
    "    return frame_file_path\n",
    "\n",
    "def get_label(sample_dir_name):\n",
    "    return 0 if sample_dir_name[0] == 'b' else 1\n",
    "\n",
    "def get_y_labels(sample_dir_names):\n",
    "    return [get_label(l) for l in sample_dir_names]\n",
    "\n",
    "def get_frames_count(root_path, sample_dir_name):\n",
    "    return len([Path(f).abspath() for f in glob(f\"{root_path}/{sample_dir_name}\" + '/*')])\n",
    "\n",
    "def get_frames(root_path, sample_dir_name):\n",
    "    frames = []\n",
    "    for frame_idx in range(0, get_frames_count(root_path, sample_dir_name)):\n",
    "        frame_file_path_template = f\"{root_path}/{sample_dir_name}/{sample_dir_name}.mov-[frame_idx]-0.csv\"\n",
    "        frame_file_path = get_frame_file_path(frame_file_path_template, frame_idx)\n",
    "        frame_data = get_frame_data(frame_file_path)\n",
    "        \n",
    "        frames.append(frame_data)\n",
    "        \n",
    "    return np.dstack(frames)\n",
    "\n",
    "def get_sample_idx_by_frames_count(frames_count, samples):\n",
    "    sample_idx = 0\n",
    "    \n",
    "    for sample in samples:\n",
    "        if len(sample) == frames_count:\n",
    "            return sample_idx\n",
    "        sample_idx = sample_idx + 1\n",
    "\n",
    "def get_sample_name_by_frames_count(frames_count, samples, sample_dir_names):\n",
    "    sample_idx = get_sample_idx_by_frames_count(frames_count, samples)\n",
    "    return sample_dir_names[sample_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['backflip-40-margus',\n",
       " 'flack-31-rasmus',\n",
       " 'flack-19-rasmus',\n",
       " 'flack-59-martin',\n",
       " 'backflip-66-allar',\n",
       " 'flack-55-martin',\n",
       " 'flack-68-rasmus',\n",
       " 'backflip-23-tiit',\n",
       " 'flack-7-hendrik',\n",
       " 'flack-4-martin',\n",
       " 'flack-15-rasmus',\n",
       " 'flack-36-hendrik',\n",
       " 'backflip-64-allar',\n",
       " 'backflip-6-rasmus',\n",
       " 'flack-82-martin',\n",
       " 'flack-35-margus',\n",
       " 'backflip-38-mario',\n",
       " 'flack-39-margus',\n",
       " 'backflip-32-hendrik',\n",
       " 'backflip-20-martin',\n",
       " 'flack-25-margus',\n",
       " 'flack-29-julia',\n",
       " 'backflip-8-rasmus',\n",
       " 'flack-80-martin',\n",
       " 'backflip-4-rasmus',\n",
       " 'backflip-54-rasmus',\n",
       " 'backflip-48-joosep',\n",
       " 'backflip-47-dagne',\n",
       " 'flack-33-rasmus',\n",
       " 'flack-61-martin',\n",
       " 'flack-17-rasmus',\n",
       " 'flack-57-martin',\n",
       " 'flack-6-hendrik',\n",
       " 'flack-37-hendrik',\n",
       " 'flack-66-rasmus',\n",
       " 'backflip-65-allar',\n",
       " 'flack-84-martin',\n",
       " 'backflip-31-hendrik',\n",
       " 'flack-62-rasmus',\n",
       " 'flack-50-kristiin',\n",
       " 'flack-70-rasmus',\n",
       " 'backflip-58-margus',\n",
       " 'backflip-25-tiit',\n",
       " 'backflip-24-tiit',\n",
       " 'backflip-63-allar',\n",
       " 'backflip-46-dagne',\n",
       " 'backflip-56-margus',\n",
       " 'backflip-39-margus',\n",
       " 'flack-79-martin',\n",
       " 'flack-47-kristiin',\n",
       " 'flack-46-kristiin',\n",
       " 'backflip-50-joosep',\n",
       " 'flack-28-julia',\n",
       " 'flack-40-margus',\n",
       " 'backflip-30-hendrik',\n",
       " 'backflip-52-rasmus',\n",
       " 'flack-9-hendrik',\n",
       " 'flack-38-hendrik',\n",
       " 'flack-83-martin',\n",
       " 'backflip-7-rasmus',\n",
       " 'flack-26-margus',\n",
       " 'flack-58-martin',\n",
       " 'backflip-27-tiit',\n",
       " 'flack-65-rasmus',\n",
       " 'backflip-43-kristjan',\n",
       " 'flack-5-martin',\n",
       " 'flack-69-rasmus',\n",
       " 'backflip-61-hendrik',\n",
       " 'flack-30-rasmus',\n",
       " 'backflip-33-mario',\n",
       " 'flack-56-martin',\n",
       " 'flack-16-rasmus',\n",
       " 'backflip-37-mario',\n",
       " 'flack-67-rasmus',\n",
       " 'flack-20-allar',\n",
       " 'flack-32-rasmus',\n",
       " 'backflip-60-hendrik',\n",
       " 'flack-60-martin',\n",
       " 'backflip-2-allar',\n",
       " 'backflip-26-tiit',\n",
       " 'flack-49-kristiin',\n",
       " 'flack-48-kristiin',\n",
       " 'backflip-49-joosep',\n",
       " 'backflip-19-martin',\n",
       " 'backflip-35-mario',\n",
       " 'backflip-55-rasmus',\n",
       " 'backflip-5-rasmus',\n",
       " 'flack-81-martin',\n",
       " 'flack-27-julia',\n",
       " 'flack-44-kristiin',\n",
       " 'flack-45-kristiin',\n",
       " 'backflip-59-margus',\n",
       " 'flack-63-rasmus',\n",
       " 'backflip-10-hendrik',\n",
       " 'flack-71-rasmus',\n",
       " 'flack-3-martin',\n",
       " 'flack-24-belinda',\n",
       " 'flack-12-rasmus',\n",
       " 'backflip-51-rasmus',\n",
       " 'backflip-1-allar',\n",
       " 'backflip-53-rasmus',\n",
       " 'backflip-34-mario',\n",
       " 'flack-34-rasmus',\n",
       " 'flack-21-allar',\n",
       " 'backflip-36-mario',\n",
       " 'backflip-57-margus',\n",
       " 'flack-78-martin',\n",
       " 'backflip-44-kristjan',\n",
       " 'backflip-45-kristjan',\n",
       " 'flack-1-martin',\n",
       " 'flack-10-rasmus',\n",
       " 'backflip-3-allar',\n",
       " 'backflip-9-hendrik']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_path = \"/Users/allarviinamae/EduWorkspace/openpose-jupyter-data-exploration/filtered-keypoints\"\n",
    "\n",
    "sample_dir_names = [n for n in os.listdir(root_path) if os.path.isdir(f\"{root_path}/{n}\")]\n",
    "\n",
    "sample_dir_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_labels = get_y_labels(sample_dir_names) # classifier labels, where 0 = backflip and 1 = flack\n",
    "\n",
    "y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "for sample_dir_name in sample_dir_names:\n",
    "    frames = get_frames(root_path, sample_dir_name)\n",
    "    squeezed = np.squeeze(frames)\n",
    "    axes_swapped = np.swapaxes(squeezed, 0, 1)\n",
    "    samples.append(axes_swapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shortest samples 77, longest sample 110\n",
      "113 (96, 50) 113\n"
     ]
    }
   ],
   "source": [
    "shortest_sample = min([len(sample) for sample in samples])\n",
    "longest_sample = max([len(sample) for sample in samples])\n",
    "\n",
    "print(f\"Shortest samples {shortest_sample}, longest sample {longest_sample}\")\n",
    "\n",
    "print(len(samples), samples[1].shape, len(y_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Samples')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(sample) for sample in samples], color = 'blue', edgecolor = 'black', bins = int(180/5))\n",
    "\n",
    "# Add labels\n",
    "plt.title('Histogram of Frames per Sample')\n",
    "plt.xlabel('Frames')\n",
    "plt.ylabel('Samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'backflip-50-joosep'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sample_name_by_frames_count(110, samples, sample_dir_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All labels shape (113, 2)\n",
      "y_label_squeezed categorical: [1. 0.]\n",
      "y_label_squeezed categorical: [0. 1.]\n",
      "y_label_squeezed categorical: [0. 1.]\n",
      "y_label_squeezed categorical: [0. 1.]\n",
      "y_label_squeezed categorical: [1. 0.]\n"
     ]
    }
   ],
   "source": [
    "y_labels_stacked = np.dstack(y_labels)\n",
    "y_labels_categorical = to_categorical(y_labels_stacked) \n",
    "y_labels_squeezed = np.squeeze(y_labels_categorical)\n",
    "print(f\"All labels shape {y_labels_squeezed.shape}\")\n",
    "\n",
    "for idx, y_label_squeezed in enumerate(y_labels_squeezed):\n",
    "    if idx == 5:\n",
    "        break\n",
    "    print(f\"y_label_squeezed categorical: {y_label_squeezed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train len 90\n",
      "y_train len 90\n",
      "X_test len 23\n",
      "y_test len 23\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(samples, y_labels_squeezed, test_size=0.2)\n",
    "\n",
    "print(f\"X_train len {len(X_train)}\")\n",
    "print(f\"y_train len {len(y_train)}\")\n",
    "\n",
    "print(f\"X_test len {len(X_test)}\")\n",
    "print(f\"y_test len {len(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(samples, y_labels):\n",
    "    while True:\n",
    "        for idx, sample in enumerate(samples):\n",
    "            (frames, features) = sample.shape\n",
    "        \n",
    "            sequence_length = frames\n",
    "            x_train = sample\n",
    "            y_train = y_labels[idx]\n",
    "        \n",
    "            x_train = x_train.reshape(1, frames, features)\n",
    "            y_train = y_train.reshape(1, 2)            \n",
    "        \n",
    "            yield x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and evaluate a model\n",
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "    verbose, epochs = 1, 10\n",
    "    \n",
    "    n_features = 50\n",
    "    n_outputs = 2\n",
    "    n_steps_per_epoch = len(trainX)\n",
    "    print(f\"Steps per epoch: {n_steps_per_epoch}\")\n",
    "    \n",
    "    lstm_units = 100\n",
    "        \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(lstm_units, input_shape=(None, 50)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(lstm_units, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    print(model.summary())\n",
    "    # fit network\n",
    "    model.fit_generator(train_generator(trainX, trainy), steps_per_epoch=n_steps_per_epoch, epochs=epochs, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy = model.evaluate_generator(train_generator(testX, testy), steps=len(testX), verbose=0)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize scores\n",
    "def summarize_results(scores):\n",
    "    print(scores)\n",
    "    m, s = mean(scores), std(scores)\n",
    "    print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run an experiment\n",
    "def run_experiment(repeats=5):\n",
    "    # repeat experiment\n",
    "    scores = list()\n",
    "    for r in range(repeats):\n",
    "        score = evaluate_model(X_train, y_train, X_test, y_test)\n",
    "        score = score * 100.0\n",
    "        print('>#%d: %.3f' % (r+1, score))\n",
    "        scores.append(score)\n",
    "    # summarize results\n",
    "    summarize_results(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps per epoch: 90\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 100)               60400     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 70,702\n",
      "Trainable params: 70,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "90/90 [==============================] - 6s 64ms/step - loss: 0.7178 - accuracy: 0.5222\n",
      "Epoch 2/10\n",
      "90/90 [==============================] - 4s 48ms/step - loss: 0.7270 - accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 0.7468 - accuracy: 0.4444\n",
      "Epoch 4/10\n",
      "90/90 [==============================] - 6s 69ms/step - loss: 0.7134 - accuracy: 0.5889\n",
      "Epoch 5/10\n",
      "90/90 [==============================] - 4s 48ms/step - loss: 0.7479 - accuracy: 0.4889\n",
      "Epoch 6/10\n",
      "90/90 [==============================] - 5s 60ms/step - loss: 0.7207 - accuracy: 0.4889\n",
      "Epoch 7/10\n",
      "90/90 [==============================] - 4s 44ms/step - loss: 0.7244 - accuracy: 0.5444\n",
      "Epoch 8/10\n",
      "90/90 [==============================] - 4s 44ms/step - loss: 0.7212 - accuracy: 0.4556\n",
      "Epoch 9/10\n",
      "90/90 [==============================] - 6s 63ms/step - loss: 0.6880 - accuracy: 0.5111\n",
      "Epoch 10/10\n",
      "90/90 [==============================] - 4s 43ms/step - loss: 0.7285 - accuracy: 0.4667\n",
      ">#1: 56.522\n",
      "Steps per epoch: 90\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 100)               60400     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 70,702\n",
      "Trainable params: 70,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.7751 - accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "90/90 [==============================] - 4s 46ms/step - loss: 0.7131 - accuracy: 0.4889\n",
      "Epoch 3/10\n",
      "90/90 [==============================] - 4s 45ms/step - loss: 0.6996 - accuracy: 0.5889\n",
      "Epoch 4/10\n",
      "90/90 [==============================] - 4s 47ms/step - loss: 0.7474 - accuracy: 0.4667\n",
      "Epoch 5/10\n",
      "90/90 [==============================] - 4s 45ms/step - loss: 0.7639 - accuracy: 0.4778\n",
      "Epoch 6/10\n",
      "90/90 [==============================] - 4s 43ms/step - loss: 0.7414 - accuracy: 0.5333\n",
      "Epoch 7/10\n",
      "90/90 [==============================] - 4s 48ms/step - loss: 0.7117 - accuracy: 0.5444\n",
      "Epoch 8/10\n",
      "90/90 [==============================] - 4s 45ms/step - loss: 0.7077 - accuracy: 0.4778\n",
      "Epoch 9/10\n",
      "90/90 [==============================] - 4s 45ms/step - loss: 0.7199 - accuracy: 0.5000\n",
      "Epoch 10/10\n",
      "90/90 [==============================] - 4s 45ms/step - loss: 0.6746 - accuracy: 0.5889\n",
      ">#2: 43.478\n",
      "Steps per epoch: 90\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 100)               60400     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 70,702\n",
      "Trainable params: 70,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "90/90 [==============================] - 5s 50ms/step - loss: 0.6914 - accuracy: 0.5889\n",
      "Epoch 2/10\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.7652 - accuracy: 0.5111\n",
      "Epoch 3/10\n",
      "90/90 [==============================] - 4s 48ms/step - loss: 0.7320 - accuracy: 0.4889\n",
      "Epoch 4/10\n",
      "90/90 [==============================] - 7s 78ms/step - loss: 0.7615 - accuracy: 0.4333\n",
      "Epoch 5/10\n",
      "90/90 [==============================] - 6s 72ms/step - loss: 0.7302 - accuracy: 0.5556\n",
      "Epoch 6/10\n",
      "90/90 [==============================] - 4s 44ms/step - loss: 0.7533 - accuracy: 0.5222\n",
      "Epoch 7/10\n",
      "90/90 [==============================] - 4s 46ms/step - loss: 0.6702 - accuracy: 0.6111\n",
      "Epoch 8/10\n",
      "90/90 [==============================] - 4s 45ms/step - loss: 0.6971 - accuracy: 0.5444\n",
      "Epoch 9/10\n",
      "90/90 [==============================] - 4s 46ms/step - loss: 0.7790 - accuracy: 0.4778\n",
      "Epoch 10/10\n",
      "90/90 [==============================] - 6s 70ms/step - loss: 0.7115 - accuracy: 0.5111\n",
      ">#3: 39.130\n",
      "Steps per epoch: 90\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 100)               60400     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 70,702\n",
      "Trainable params: 70,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "90/90 [==============================] - 7s 76ms/step - loss: 0.7316 - accuracy: 0.5667\n",
      "Epoch 2/10\n",
      "90/90 [==============================] - 6s 71ms/step - loss: 0.7990 - accuracy: 0.4333\n",
      "Epoch 3/10\n",
      "90/90 [==============================] - 7s 73ms/step - loss: 0.7207 - accuracy: 0.5222\n",
      "Epoch 4/10\n",
      "90/90 [==============================] - 7s 72ms/step - loss: 0.7709 - accuracy: 0.4667\n",
      "Epoch 5/10\n",
      "90/90 [==============================] - 6s 70ms/step - loss: 0.7099 - accuracy: 0.5667\n",
      "Epoch 6/10\n",
      "90/90 [==============================] - 7s 74ms/step - loss: 0.7222 - accuracy: 0.5444\n",
      "Epoch 7/10\n",
      "90/90 [==============================] - 6s 70ms/step - loss: 0.7264 - accuracy: 0.5444\n",
      "Epoch 8/10\n",
      "90/90 [==============================] - 4s 45ms/step - loss: 0.7201 - accuracy: 0.5667\n",
      "Epoch 9/10\n",
      "90/90 [==============================] - 4s 46ms/step - loss: 0.7641 - accuracy: 0.4556\n",
      "Epoch 10/10\n",
      "90/90 [==============================] - 5s 55ms/step - loss: 0.7245 - accuracy: 0.5111\n",
      ">#4: 69.565\n",
      "Steps per epoch: 90\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 100)               60400     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 70,702\n",
      "Trainable params: 70,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "90/90 [==============================] - 4s 50ms/step - loss: 0.6929 - accuracy: 0.5556\n",
      "Epoch 2/10\n",
      "90/90 [==============================] - 4s 48ms/step - loss: 0.7272 - accuracy: 0.4667\n",
      "Epoch 3/10\n",
      "90/90 [==============================] - 5s 59ms/step - loss: 0.7487 - accuracy: 0.4556\n",
      "Epoch 4/10\n",
      "90/90 [==============================] - 6s 65ms/step - loss: 0.7331 - accuracy: 0.4889\n",
      "Epoch 5/10\n",
      "90/90 [==============================] - 6s 68ms/step - loss: 0.7348 - accuracy: 0.5667\n",
      "Epoch 6/10\n",
      "90/90 [==============================] - 6s 69ms/step - loss: 0.7498 - accuracy: 0.4222\n",
      "Epoch 7/10\n",
      "90/90 [==============================] - 6s 67ms/step - loss: 0.7237 - accuracy: 0.5000\n",
      "Epoch 8/10\n",
      "90/90 [==============================] - 6s 66ms/step - loss: 0.7329 - accuracy: 0.4556\n",
      "Epoch 9/10\n",
      "90/90 [==============================] - 7s 73ms/step - loss: 0.6826 - accuracy: 0.5444\n",
      "Epoch 10/10\n",
      "90/90 [==============================] - 6s 64ms/step - loss: 0.6898 - accuracy: 0.5222\n",
      ">#5: 60.870\n",
      "[56.521737575531006, 43.478259444236755, 39.13043439388275, 69.5652186870575, 60.86956262588501]\n",
      "Accuracy: 53.913% (+/-11.204)\n"
     ]
    }
   ],
   "source": [
    "run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openpose-jupyter-data-exploration",
   "language": "python",
   "name": "openpose-jupyter-data-exploration"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
